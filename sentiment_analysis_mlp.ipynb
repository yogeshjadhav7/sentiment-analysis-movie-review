{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_file = \"train_data.csv\"\n",
    "test_file = \"test_data.csv\"\n",
    "\n",
    "TRAIN_MODEL = True\n",
    "MODEL_NAME = \"trained_model_mlp.hdf5\"\n",
    "\n",
    "def load_data(file, direc=\"\", sep=\",\", header=True):\n",
    "    csv_path = os.path.join(direc, file)\n",
    "    if header:\n",
    "        return pd.read_csv(csv_path, sep=sep, index_col=False)\n",
    "    else:\n",
    "        return pd.read_csv(csv_path, sep=sep, index_col=False, header=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.293233</td>\n",
       "      <td>0.075336</td>\n",
       "      <td>-0.265466</td>\n",
       "      <td>-0.356092</td>\n",
       "      <td>0.066430</td>\n",
       "      <td>0.761425</td>\n",
       "      <td>-0.001033</td>\n",
       "      <td>-0.340051</td>\n",
       "      <td>-0.140389</td>\n",
       "      <td>-0.384717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.304356</td>\n",
       "      <td>0.110543</td>\n",
       "      <td>-0.257856</td>\n",
       "      <td>0.248262</td>\n",
       "      <td>0.304541</td>\n",
       "      <td>-0.454722</td>\n",
       "      <td>0.313093</td>\n",
       "      <td>0.096131</td>\n",
       "      <td>0.022209</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.281317</td>\n",
       "      <td>-0.052475</td>\n",
       "      <td>-0.227652</td>\n",
       "      <td>-0.145945</td>\n",
       "      <td>0.129469</td>\n",
       "      <td>0.254899</td>\n",
       "      <td>0.192881</td>\n",
       "      <td>-0.210649</td>\n",
       "      <td>-0.311281</td>\n",
       "      <td>0.397568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147703</td>\n",
       "      <td>-0.144117</td>\n",
       "      <td>0.197492</td>\n",
       "      <td>0.157018</td>\n",
       "      <td>0.054766</td>\n",
       "      <td>-0.073626</td>\n",
       "      <td>0.093853</td>\n",
       "      <td>0.080051</td>\n",
       "      <td>-0.250832</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065311</td>\n",
       "      <td>0.078494</td>\n",
       "      <td>0.018382</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>-0.185517</td>\n",
       "      <td>-0.062630</td>\n",
       "      <td>0.390812</td>\n",
       "      <td>0.222266</td>\n",
       "      <td>0.223175</td>\n",
       "      <td>-0.437040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391639</td>\n",
       "      <td>-0.040531</td>\n",
       "      <td>0.092544</td>\n",
       "      <td>-0.397565</td>\n",
       "      <td>0.517327</td>\n",
       "      <td>-0.164458</td>\n",
       "      <td>0.110916</td>\n",
       "      <td>0.456602</td>\n",
       "      <td>-0.073503</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.123459</td>\n",
       "      <td>0.029362</td>\n",
       "      <td>0.058820</td>\n",
       "      <td>-0.235124</td>\n",
       "      <td>0.156227</td>\n",
       "      <td>0.575867</td>\n",
       "      <td>0.266410</td>\n",
       "      <td>-0.644778</td>\n",
       "      <td>-0.046550</td>\n",
       "      <td>-0.047256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125449</td>\n",
       "      <td>-0.121503</td>\n",
       "      <td>-0.549419</td>\n",
       "      <td>0.024966</td>\n",
       "      <td>0.150538</td>\n",
       "      <td>-0.302210</td>\n",
       "      <td>0.330751</td>\n",
       "      <td>-0.321547</td>\n",
       "      <td>-0.021141</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.417293</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>0.499212</td>\n",
       "      <td>-0.309810</td>\n",
       "      <td>-0.079425</td>\n",
       "      <td>-0.137011</td>\n",
       "      <td>0.228430</td>\n",
       "      <td>-0.066997</td>\n",
       "      <td>0.284044</td>\n",
       "      <td>0.465361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143851</td>\n",
       "      <td>-0.092237</td>\n",
       "      <td>-0.244069</td>\n",
       "      <td>0.222020</td>\n",
       "      <td>-0.360323</td>\n",
       "      <td>-0.032631</td>\n",
       "      <td>-0.143966</td>\n",
       "      <td>-0.087031</td>\n",
       "      <td>-0.474025</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.293233  0.075336 -0.265466 -0.356092  0.066430  0.761425 -0.001033   \n",
       "1 -0.281317 -0.052475 -0.227652 -0.145945  0.129469  0.254899  0.192881   \n",
       "2  0.065311  0.078494  0.018382 -0.024447 -0.185517 -0.062630  0.390812   \n",
       "3  0.123459  0.029362  0.058820 -0.235124  0.156227  0.575867  0.266410   \n",
       "4 -0.417293  0.007130  0.499212 -0.309810 -0.079425 -0.137011  0.228430   \n",
       "\n",
       "          7         8         9    ...           216       217       218  \\\n",
       "0 -0.340051 -0.140389 -0.384717    ...     -0.304356  0.110543 -0.257856   \n",
       "1 -0.210649 -0.311281  0.397568    ...      0.147703 -0.144117  0.197492   \n",
       "2  0.222266  0.223175 -0.437040    ...      0.391639 -0.040531  0.092544   \n",
       "3 -0.644778 -0.046550 -0.047256    ...      0.125449 -0.121503 -0.549419   \n",
       "4 -0.066997  0.284044  0.465361    ...      0.143851 -0.092237 -0.244069   \n",
       "\n",
       "        219       220       221       222       223       224  Sentiment  \n",
       "0  0.248262  0.304541 -0.454722  0.313093  0.096131  0.022209        1.0  \n",
       "1  0.157018  0.054766 -0.073626  0.093853  0.080051 -0.250832        0.0  \n",
       "2 -0.397565  0.517327 -0.164458  0.110916  0.456602 -0.073503        0.0  \n",
       "3  0.024966  0.150538 -0.302210  0.330751 -0.321547 -0.021141        1.0  \n",
       "4  0.222020 -0.360323 -0.032631 -0.143966 -0.087031 -0.474025        1.0  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109306</td>\n",
       "      <td>0.192315</td>\n",
       "      <td>-0.032794</td>\n",
       "      <td>0.152092</td>\n",
       "      <td>0.108466</td>\n",
       "      <td>0.081162</td>\n",
       "      <td>-0.143557</td>\n",
       "      <td>0.087043</td>\n",
       "      <td>0.225055</td>\n",
       "      <td>-0.240789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189616</td>\n",
       "      <td>0.036832</td>\n",
       "      <td>0.027846</td>\n",
       "      <td>-0.331823</td>\n",
       "      <td>-0.037055</td>\n",
       "      <td>0.222175</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.210313</td>\n",
       "      <td>0.229882</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.124460</td>\n",
       "      <td>0.135917</td>\n",
       "      <td>0.431114</td>\n",
       "      <td>0.262919</td>\n",
       "      <td>0.010424</td>\n",
       "      <td>0.204219</td>\n",
       "      <td>-0.222301</td>\n",
       "      <td>0.120114</td>\n",
       "      <td>-0.051119</td>\n",
       "      <td>-0.118828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020186</td>\n",
       "      <td>0.185100</td>\n",
       "      <td>0.328118</td>\n",
       "      <td>0.036923</td>\n",
       "      <td>-0.085293</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>-0.198617</td>\n",
       "      <td>0.033985</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.211367</td>\n",
       "      <td>0.194651</td>\n",
       "      <td>-0.231363</td>\n",
       "      <td>-0.311015</td>\n",
       "      <td>0.092923</td>\n",
       "      <td>0.164169</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>-0.143032</td>\n",
       "      <td>0.253581</td>\n",
       "      <td>-0.160928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193897</td>\n",
       "      <td>0.304636</td>\n",
       "      <td>-0.146392</td>\n",
       "      <td>-0.102875</td>\n",
       "      <td>-0.131144</td>\n",
       "      <td>-0.182048</td>\n",
       "      <td>-0.040771</td>\n",
       "      <td>-0.037335</td>\n",
       "      <td>0.028673</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.082641</td>\n",
       "      <td>-0.154188</td>\n",
       "      <td>-0.111012</td>\n",
       "      <td>-0.165968</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>-0.151640</td>\n",
       "      <td>0.027495</td>\n",
       "      <td>-0.121806</td>\n",
       "      <td>0.322140</td>\n",
       "      <td>0.095643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106269</td>\n",
       "      <td>-0.169688</td>\n",
       "      <td>0.201560</td>\n",
       "      <td>0.021454</td>\n",
       "      <td>0.247993</td>\n",
       "      <td>0.132580</td>\n",
       "      <td>0.071670</td>\n",
       "      <td>-0.093814</td>\n",
       "      <td>-0.190500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.022724</td>\n",
       "      <td>0.149019</td>\n",
       "      <td>0.319221</td>\n",
       "      <td>-0.033267</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>-0.029595</td>\n",
       "      <td>0.236312</td>\n",
       "      <td>0.370445</td>\n",
       "      <td>-0.128876</td>\n",
       "      <td>0.155701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138224</td>\n",
       "      <td>0.084814</td>\n",
       "      <td>0.122257</td>\n",
       "      <td>0.099517</td>\n",
       "      <td>0.144641</td>\n",
       "      <td>0.234967</td>\n",
       "      <td>-0.030566</td>\n",
       "      <td>-0.088829</td>\n",
       "      <td>-0.206466</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.109306  0.192315 -0.032794  0.152092  0.108466  0.081162 -0.143557   \n",
       "1 -0.124460  0.135917  0.431114  0.262919  0.010424  0.204219 -0.222301   \n",
       "2  0.211367  0.194651 -0.231363 -0.311015  0.092923  0.164169  0.003516   \n",
       "3  0.082641 -0.154188 -0.111012 -0.165968 -0.017690 -0.151640  0.027495   \n",
       "4 -0.022724  0.149019  0.319221 -0.033267  0.012244 -0.029595  0.236312   \n",
       "\n",
       "          7         8         9    ...           216       217       218  \\\n",
       "0  0.087043  0.225055 -0.240789    ...     -0.189616  0.036832  0.027846   \n",
       "1  0.120114 -0.051119 -0.118828    ...     -0.020186  0.185100  0.328118   \n",
       "2 -0.143032  0.253581 -0.160928    ...     -0.193897  0.304636 -0.146392   \n",
       "3 -0.121806  0.322140  0.095643    ...     -0.106269 -0.169688  0.201560   \n",
       "4  0.370445 -0.128876  0.155701    ...      0.138224  0.084814  0.122257   \n",
       "\n",
       "        219       220       221       222       223       224  Sentiment  \n",
       "0 -0.331823 -0.037055  0.222175 -0.410430 -0.210313  0.229882        1.0  \n",
       "1  0.036923 -0.085293  0.012201 -0.198617  0.033985  0.003320        0.0  \n",
       "2 -0.102875 -0.131144 -0.182048 -0.040771 -0.037335  0.028673        0.0  \n",
       "3  0.021454  0.247993  0.132580  0.071670 -0.093814 -0.190500        0.0  \n",
       "4  0.099517  0.144641  0.234967 -0.030566 -0.088829 -0.206466        1.0  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.int16(train_data[\"Sentiment\"].copy().values)\n",
    "train_features = train_data.drop(\"Sentiment\", axis=1)\n",
    "\n",
    "test_labels = np.int16(test_data[\"Sentiment\"].copy().values)\n",
    "test_features = test_data.drop(\"Sentiment\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(train_features)\n",
    "\n",
    "train_features = scalar.transform(train_features)\n",
    "test_features = scalar.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_roc_curve(clf_sets):\n",
    "    for clf_set in clf_sets:\n",
    "        y = clf_set[0]\n",
    "        y_pred = clf_set[1]\n",
    "        label = clf_set[2]\n",
    "        fpr, tpr, thresholds = roc_curve(y, y_pred)\n",
    "        plt.plot(fpr, tpr, linewidth=1, label=label)\n",
    "    \n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.axis([0,1,0,1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"bottom right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_features.copy()\n",
    "Y = train_labels.copy()\n",
    "X_test = test_features.copy()\n",
    "Y_test = test_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              16384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 721,730\n",
      "Trainable params: 717,762\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have shape (15,) but got array with shape (225,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f001dd68d895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                         \u001b[0;31m#callbacks=callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                        )\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1638\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1481\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1484\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1485\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have shape (15,) but got array with shape (225,)"
     ]
    }
   ],
   "source": [
    "\n",
    "# CNN Classifier\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "size = np.int16(X.shape[1])\n",
    "\n",
    "train_x = X.copy()\n",
    "test_x = X_test.copy()\n",
    "\n",
    "train_y = to_categorical(Y)\n",
    "test_y = to_categorical(Y_test)\n",
    "\n",
    "num_classes = train_y.shape[1]\n",
    "droprate = 0.8\n",
    "\n",
    "try:\n",
    "    model = load_model(MODEL_NAME)\n",
    "except:\n",
    "    model = None\n",
    "    \n",
    "ACT = 'tanh'    \n",
    "    \n",
    "if model is None:\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(1024, activation=ACT, input_shape=(size,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Dense(512, activation=ACT))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Dense(512, activation=ACT))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Dense(256, activation=ACT))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Dense(128, activation=ACT))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Dense(64, activation=ACT))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Dense(32, activation=ACT))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Dense(16, activation=ACT))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    adam = Adam()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "else:\n",
    "    print(MODEL_NAME, \" is restored.\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [ModelCheckpoint(MODEL_NAME, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)]\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    history = model.fit(train_x, train_y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=0,\n",
    "                        validation_data=(test_x, test_y),\n",
    "                        callbacks=callbacks)\n",
    "else:\n",
    "    print(\"Opted not to train the model as TRAIN_MODEL is set to False. May be because model is already trained and is now being used for validation\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = load_model(MODEL_NAME)\n",
    "score = saved_model.evaluate(test_x, test_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
