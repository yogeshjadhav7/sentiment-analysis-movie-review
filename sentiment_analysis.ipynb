{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_file = \"train_data.csv\"\n",
    "test_file = \"test_data.csv\"\n",
    "\n",
    "def load_data(file, direc=\"\", sep=\",\", header=True):\n",
    "    csv_path = os.path.join(direc, file)\n",
    "    if header:\n",
    "        return pd.read_csv(csv_path, sep=sep, index_col=False)\n",
    "    else:\n",
    "        return pd.read_csv(csv_path, sep=sep, index_col=False, header=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.190214</td>\n",
       "      <td>-0.775909</td>\n",
       "      <td>0.606918</td>\n",
       "      <td>-0.422152</td>\n",
       "      <td>1.006142</td>\n",
       "      <td>-1.099935</td>\n",
       "      <td>-0.591228</td>\n",
       "      <td>0.110556</td>\n",
       "      <td>-0.685102</td>\n",
       "      <td>0.233484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.406460</td>\n",
       "      <td>-0.145558</td>\n",
       "      <td>-1.306575</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.624839</td>\n",
       "      <td>-1.368549</td>\n",
       "      <td>0.805194</td>\n",
       "      <td>-0.758950</td>\n",
       "      <td>0.145932</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.248992</td>\n",
       "      <td>-0.204263</td>\n",
       "      <td>0.585718</td>\n",
       "      <td>-0.340346</td>\n",
       "      <td>0.623218</td>\n",
       "      <td>-0.132182</td>\n",
       "      <td>-0.446606</td>\n",
       "      <td>-0.085173</td>\n",
       "      <td>0.247781</td>\n",
       "      <td>-0.290398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172685</td>\n",
       "      <td>0.630882</td>\n",
       "      <td>0.110635</td>\n",
       "      <td>0.223473</td>\n",
       "      <td>0.180395</td>\n",
       "      <td>0.131066</td>\n",
       "      <td>0.163105</td>\n",
       "      <td>0.723476</td>\n",
       "      <td>-0.002338</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040464</td>\n",
       "      <td>1.032194</td>\n",
       "      <td>-0.982082</td>\n",
       "      <td>-0.054039</td>\n",
       "      <td>0.172879</td>\n",
       "      <td>0.061846</td>\n",
       "      <td>0.513306</td>\n",
       "      <td>-0.427153</td>\n",
       "      <td>0.800728</td>\n",
       "      <td>-0.842768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071184</td>\n",
       "      <td>0.454823</td>\n",
       "      <td>-0.388393</td>\n",
       "      <td>-0.455052</td>\n",
       "      <td>0.816787</td>\n",
       "      <td>-0.742167</td>\n",
       "      <td>0.423050</td>\n",
       "      <td>0.541922</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.102443</td>\n",
       "      <td>-0.471759</td>\n",
       "      <td>0.036330</td>\n",
       "      <td>0.192056</td>\n",
       "      <td>1.049041</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>-0.082436</td>\n",
       "      <td>-0.192707</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>0.224525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502373</td>\n",
       "      <td>-0.552040</td>\n",
       "      <td>-0.389139</td>\n",
       "      <td>0.310724</td>\n",
       "      <td>-0.114863</td>\n",
       "      <td>0.532303</td>\n",
       "      <td>-0.150409</td>\n",
       "      <td>0.128998</td>\n",
       "      <td>-0.101038</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029157</td>\n",
       "      <td>-0.296443</td>\n",
       "      <td>0.683454</td>\n",
       "      <td>0.026448</td>\n",
       "      <td>-0.729840</td>\n",
       "      <td>1.183778</td>\n",
       "      <td>0.836208</td>\n",
       "      <td>0.700741</td>\n",
       "      <td>-0.260888</td>\n",
       "      <td>-0.136369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.318998</td>\n",
       "      <td>-0.120458</td>\n",
       "      <td>0.013771</td>\n",
       "      <td>-0.661265</td>\n",
       "      <td>-0.215869</td>\n",
       "      <td>-1.508247</td>\n",
       "      <td>0.381819</td>\n",
       "      <td>-0.027416</td>\n",
       "      <td>-0.900369</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.190214 -0.775909  0.606918 -0.422152  1.006142 -1.099935 -0.591228   \n",
       "1 -0.248992 -0.204263  0.585718 -0.340346  0.623218 -0.132182 -0.446606   \n",
       "2  0.040464  1.032194 -0.982082 -0.054039  0.172879  0.061846  0.513306   \n",
       "3 -0.102443 -0.471759  0.036330  0.192056  1.049041  0.023328 -0.082436   \n",
       "4  0.029157 -0.296443  0.683454  0.026448 -0.729840  1.183778  0.836208   \n",
       "\n",
       "          7         8         9    ...           280       281       282  \\\n",
       "0  0.110556 -0.685102  0.233484    ...     -0.406460 -0.145558 -1.306575   \n",
       "1 -0.085173  0.247781 -0.290398    ...     -0.172685  0.630882  0.110635   \n",
       "2 -0.427153  0.800728 -0.842768    ...     -0.071184  0.454823 -0.388393   \n",
       "3 -0.192707 -0.043875  0.224525    ...      0.502373 -0.552040 -0.389139   \n",
       "4  0.700741 -0.260888 -0.136369    ...     -0.318998 -0.120458  0.013771   \n",
       "\n",
       "        283       284       285       286       287       288  Sentiment  \n",
       "0  0.230331  0.624839 -1.368549  0.805194 -0.758950  0.145932        1.0  \n",
       "1  0.223473  0.180395  0.131066  0.163105  0.723476 -0.002338        0.0  \n",
       "2 -0.455052  0.816787 -0.742167  0.423050  0.541922 -0.391158        1.0  \n",
       "3  0.310724 -0.114863  0.532303 -0.150409  0.128998 -0.101038        1.0  \n",
       "4 -0.661265 -0.215869 -1.508247  0.381819 -0.027416 -0.900369        0.0  \n",
       "\n",
       "[5 rows x 290 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.224514</td>\n",
       "      <td>-0.269337</td>\n",
       "      <td>0.149535</td>\n",
       "      <td>-0.204498</td>\n",
       "      <td>-0.319069</td>\n",
       "      <td>-0.178723</td>\n",
       "      <td>0.249171</td>\n",
       "      <td>0.177335</td>\n",
       "      <td>-0.430412</td>\n",
       "      <td>-0.079033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477580</td>\n",
       "      <td>0.326845</td>\n",
       "      <td>0.422710</td>\n",
       "      <td>-0.071163</td>\n",
       "      <td>-0.674291</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.018685</td>\n",
       "      <td>-0.334325</td>\n",
       "      <td>0.639806</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.428177</td>\n",
       "      <td>0.066324</td>\n",
       "      <td>0.035085</td>\n",
       "      <td>-0.386542</td>\n",
       "      <td>-0.237192</td>\n",
       "      <td>0.059233</td>\n",
       "      <td>-0.268529</td>\n",
       "      <td>0.356585</td>\n",
       "      <td>0.095090</td>\n",
       "      <td>-0.367670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086699</td>\n",
       "      <td>0.465709</td>\n",
       "      <td>-0.067263</td>\n",
       "      <td>-0.474439</td>\n",
       "      <td>-0.090253</td>\n",
       "      <td>-0.149597</td>\n",
       "      <td>-0.047571</td>\n",
       "      <td>-0.148241</td>\n",
       "      <td>-0.014998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000866</td>\n",
       "      <td>-0.354202</td>\n",
       "      <td>-0.428207</td>\n",
       "      <td>-0.127960</td>\n",
       "      <td>0.188175</td>\n",
       "      <td>-0.415807</td>\n",
       "      <td>0.359235</td>\n",
       "      <td>0.047495</td>\n",
       "      <td>0.167235</td>\n",
       "      <td>-0.148469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468923</td>\n",
       "      <td>-0.178838</td>\n",
       "      <td>0.158628</td>\n",
       "      <td>0.260055</td>\n",
       "      <td>0.042674</td>\n",
       "      <td>-0.051289</td>\n",
       "      <td>0.167824</td>\n",
       "      <td>-0.244007</td>\n",
       "      <td>-0.143949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.094622</td>\n",
       "      <td>-0.015890</td>\n",
       "      <td>0.131040</td>\n",
       "      <td>0.235522</td>\n",
       "      <td>0.344240</td>\n",
       "      <td>0.094459</td>\n",
       "      <td>-0.260801</td>\n",
       "      <td>-0.167188</td>\n",
       "      <td>-0.103057</td>\n",
       "      <td>0.209749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128503</td>\n",
       "      <td>-0.116131</td>\n",
       "      <td>-0.026830</td>\n",
       "      <td>-0.217328</td>\n",
       "      <td>0.366705</td>\n",
       "      <td>-0.037544</td>\n",
       "      <td>-0.442792</td>\n",
       "      <td>0.306934</td>\n",
       "      <td>0.205799</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.419940</td>\n",
       "      <td>0.225918</td>\n",
       "      <td>0.188928</td>\n",
       "      <td>0.090584</td>\n",
       "      <td>-0.360560</td>\n",
       "      <td>-0.180346</td>\n",
       "      <td>0.190001</td>\n",
       "      <td>0.260009</td>\n",
       "      <td>0.066459</td>\n",
       "      <td>0.268290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>0.333524</td>\n",
       "      <td>-0.011516</td>\n",
       "      <td>-0.129948</td>\n",
       "      <td>-0.256695</td>\n",
       "      <td>-0.075641</td>\n",
       "      <td>0.134001</td>\n",
       "      <td>-0.198112</td>\n",
       "      <td>-0.013948</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.224514 -0.269337  0.149535 -0.204498 -0.319069 -0.178723  0.249171   \n",
       "1 -0.428177  0.066324  0.035085 -0.386542 -0.237192  0.059233 -0.268529   \n",
       "2  0.000866 -0.354202 -0.428207 -0.127960  0.188175 -0.415807  0.359235   \n",
       "3  0.094622 -0.015890  0.131040  0.235522  0.344240  0.094459 -0.260801   \n",
       "4  0.419940  0.225918  0.188928  0.090584 -0.360560 -0.180346  0.190001   \n",
       "\n",
       "          7         8         9    ...           280       281       282  \\\n",
       "0  0.177335 -0.430412 -0.079033    ...      0.477580  0.326845  0.422710   \n",
       "1  0.356585  0.095090 -0.367670    ...     -0.086699  0.465709 -0.067263   \n",
       "2  0.047495  0.167235 -0.148469    ...      0.468923 -0.178838  0.158628   \n",
       "3 -0.167188 -0.103057  0.209749    ...     -0.128503 -0.116131 -0.026830   \n",
       "4  0.260009  0.066459  0.268290    ...      0.014408  0.333524 -0.011516   \n",
       "\n",
       "        283       284       285       286       287       288  Sentiment  \n",
       "0 -0.071163 -0.674291  0.361922 -0.018685 -0.334325  0.639806        0.0  \n",
       "1 -0.474439 -0.090253 -0.149597 -0.047571 -0.148241 -0.014998        1.0  \n",
       "2  0.260055  0.042674 -0.051289  0.167824 -0.244007 -0.143949        0.0  \n",
       "3 -0.217328  0.366705 -0.037544 -0.442792  0.306934  0.205799        0.0  \n",
       "4 -0.129948 -0.256695 -0.075641  0.134001 -0.198112 -0.013948        0.0  \n",
       "\n",
       "[5 rows x 290 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.int16(train_data[\"Sentiment\"].copy().values)\n",
    "train_features = train_data.drop(\"Sentiment\", axis=1)\n",
    "\n",
    "test_labels = np.int16(test_data[\"Sentiment\"].copy().values)\n",
    "test_features = test_data.drop(\"Sentiment\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(train_features)\n",
    "\n",
    "train_features = scalar.transform(train_features)\n",
    "test_features = scalar.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_roc_curve(clf_sets):\n",
    "    for clf_set in clf_sets:\n",
    "        y = clf_set[0]\n",
    "        y_pred = clf_set[1]\n",
    "        label = clf_set[2]\n",
    "        fpr, tpr, thresholds = roc_curve(y, y_pred)\n",
    "        plt.plot(fpr, tpr, linewidth=1, label=label)\n",
    "    \n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.axis([0,1,0,1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"bottom right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_features.copy()\n",
    "Y = train_labels.copy()\n",
    "X_test = test_features.copy()\n",
    "Y_test = test_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CNN Classifier\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 25\n",
    "TRAIN_MODEL = True\n",
    "MODEL_NAME = \"trained_model.h5\"\n",
    "\n",
    "size = np.int16(np.sqrt(X.shape[1]))\n",
    "\n",
    "train_x = np.reshape(X, (-1, size, size, 1))\n",
    "test_x = np.reshape(X_test, (-1, size, size, 1))\n",
    "\n",
    "#binarizer = LabelBinarizer()\n",
    "#binarizer.fit(Y)\n",
    "#train_y = binarizer.transform(Y)\n",
    "#test_y = binarizer.transform(Y_test)\n",
    "\n",
    "train_y = Y\n",
    "test_y = Y_test\n",
    "\n",
    "num_classes = 1 #len(binarizer.classes_)\n",
    "print(num_classes)\n",
    "droprate = 0.7\n",
    "\n",
    "try:\n",
    "    model = load_model(MODEL_NAME)\n",
    "except:\n",
    "    model = None\n",
    "\n",
    "if model is None:\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='elu', input_shape=(size, size, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='elu', padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='elu', padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='elu', padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dropout(droprate))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Dense(128, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Dense(64, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Dense(32, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "else:\n",
    "    print(MODEL_NAME, \" is restored.\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "adam = Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [ModelCheckpoint(MODEL_NAME, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)]\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    history = model.fit(train_x, train_y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(test_x, test_y),\n",
    "                        callbacks=callbacks)\n",
    "else:\n",
    "    print(\"Opted not to train the model as TRAIN_MODEL is set to False. May be because model is already trained and is now being used for validation\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = load_model(MODEL_NAME)\n",
    "score = saved_model.evaluate(test_x, test_y, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
